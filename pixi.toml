[workspace]
channels = ["nvidia", "conda-forge"]
name = "inference-hive"
platforms = ["linux-64"]
version = "0.1.0"

[tasks]

[dependencies]
python = "3.12.*"

[pypi-dependencies]
loguru = ">=0.7.3"
pyyaml = ">=6.0.2"
pydantic = ">=2.11.7"
tqdm = ">=4.67.1"
huggingface-hub = ">=0.32.4"
datasets = ">=3.6.0"
transformers = ">=4.52.3"
openai = ">=1.86.0"
polars = ">=1.30.0"
tabulate = ">=0.9.0"
hf-transfer = ">=0.1.9"

[feature.cpu]
platforms = ["linux-64"]

[feature.cpu.pypi-dependencies]
torch = {version = "==2.8.0", index="https://download.pytorch.org/whl/cpu"}

[feature.cpu.dependencies]
jupyter = ">=1.1.1,<2"

[feature.cuda-vllm]
platforms = ["linux-64"]

[feature.cuda-vllm.dependencies]
cuda-toolkit = "12.8.*"

[feature.cuda-vllm.pypi-dependencies]
torch = {version = "==2.7.0", index="https://download.pytorch.org/whl/cu128"}
vllm = "==0.9.1"

[feature.cuda-sglang.dependencies]
cuda-toolkit = "12.8.*"

[feature.cuda-sglang.pypi-dependencies]
torch = {version = "==2.8.0", index="https://download.pytorch.org/whl/cu128"}
sglang = {version = "==0.5.2", extras = ["all"]}

# ToDo: amd rocm env for lumi
# ToDo: aarch64 cuda env for jupiter

[environments]
cpu = ["cpu"]
cuda-vllm = ["cuda-vllm"]
cuda-sglang = ["cuda-sglang"]
